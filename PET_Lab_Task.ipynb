{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PET_Lab_Task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FpHCiceYNsy"
      },
      "source": [
        "# Total Variation (TV) regularizáció PET rekonstrukcióhoz\n",
        "\n",
        "A [pozitronemissziós tomográfia (PET)](https://hu.wikipedia.org/wiki/Pozitronemisszi%C3%B3s_tomogr%C3%A1fia) egy orvosi képalkotó eljárás, aminek során radioaktív nyomjelző anyagot juttatnak a páciensbe, amely nyomjelző felhalmozódik a tumorban és γ-sugárzás kibocsátásával felfedi annak helyét. A tomográf γ-fotonpárok becsapódását érzékeli, és ezekből a becsapódási adatokból kell szoftveresen rekonstruálni a páciens testét. A rekonstrukciót a [maximum-likelihood expectation-maximization (ML-EM)](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm) algoritmussal szokás végezni. Az ML-EM azonban sokszor zajos képet eredményez, ezért *regularizációra* van szükség. A [total variation (TV) regularizáció](https://en.wikipedia.org/wiki/Total_variation_denoising) egy olyan szűrési eljárás, amely a kimeneti kép *teljes varianciáját* (a kép gradiensének abszolút értékének az integrálját) csökkenti, mivel a nagy varianciát szinte mindig a zaj okozza. Ha a varianciát el tudjuk nyomni úgy, hogy az előálló kép a lehető legközelebb legyen a bemenethez, akkor lényegében *zajtalanítjuk* a bemeneti képet. TV regularizációt a PET rekonstrukcióban úgy tudunk alkalmazni, hogy az ML-EM által minimalizált célfüggvénybe beillesztjük a *„+ λ⋅TV(x)”* tagot, ahol a *TV(x)* az aktuális nyomjelzőeloszlás-becslés (*x*) teljes varianciája és λ a regularizáció erőssége. (Minél nagyobb λ értéke, annál erősebb a regularizáció hatása, viszont annál inkább jelenhet meg nem kívánt elmosás.) A λ ideális értéke az ML-EM rekonstrukció során iterációról iterációra változhat, így a fix értéken rögzítés nem ad optimális eredményt, a kézzel történő beállítása azonban nem kivitelezhető (nincs rá ember, idő, illetve módszer). A mai gyakorlaton egy enkóder-dekóder neurális hálózatot fogunk betanítani a TV regularizáció λ paraméterének finomhangolására az ML-EM rekonstrukcióhoz."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importok és inicializálás"
      ],
      "metadata": {
        "id": "bWAT5_G2q0xZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzfvJkhfSnOc"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, Dense, Activation, Concatenate, Lambda, Flatten\n",
        "from keras.layers import MaxPooling2D, AveragePooling2D, UpSampling2D, Conv2DTranspose\n",
        "from keras.layers import BatchNormalization, Dropout\n",
        "from keras.utils.vis_utils import plot_model \n",
        "import keras.callbacks\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interact, widgets\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JnbpyYOYSaH"
      },
      "source": [
        "## Adatok letöltése\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svDplvsulXcK"
      },
      "source": [
        "!wget http://cg.iit.bme.hu/~drnyu/dlvizinf/pet_lab_input_data.zip\n",
        "!unzip pet_lab_input_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwAa4h-4YVLq"
      },
      "source": [
        "## Adatok betöltése\n",
        "\n",
        "Adott a következő segédfüggvény az adatok betöltéséhez:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miNyWLR6slsQ"
      },
      "source": [
        "def load_data(dir):\n",
        "    data = {}\n",
        "    data['xin'] = np.load(dir + \"/xin.npy\")\n",
        "    data['gradient'] = np.load(dir + \"/gradient.npy\")\n",
        "    data['numerator'] = np.load(dir + \"/numerator.npy\")\n",
        "    data['denominator'] = np.load(dir + \"/denominator.npy\")\n",
        "    data['reference'] = np.load(dir + \"/reference.npy\")\n",
        "    data['global_tv'] = np.load(dir + \"/global_tv.npy\")\n",
        "    # Remark: data arrays have a shape of (n_samples, height, width, channels)\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V1LDpdJYYGz"
      },
      "source": [
        "Feladat:\n",
        "\n",
        "* Inicializáljátok a *xin*, *gradient*, *numerator*, *denominator*, *reference* változókat a betöltött adatokból!\n",
        "* Keverjétek meg az adatokat egy random permutáció alkalmazásával úgy, hogy a változók közötti összhang a keverés után is megmaradjon! (Tipp: a [numpy.random.permutation](https://numpy.org/doc/stable/reference/random/generated/numpy.random.permutation.html) permutált tartományt ad vissza.)\n",
        "* A gyorsabb tanítás érdekében most csak az első 50.000 mintával fogunk dolgozni. Dobjátok el a többit!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsPuM_KBo9iF"
      },
      "source": [
        "data = load_data('./pet_lab_input_data')\n",
        "\n",
        "perm = None\n",
        "\n",
        "xin         = None\n",
        "gradient    = None\n",
        "numerator   = None\n",
        "denominator = None\n",
        "reference   = None\n",
        "\n",
        "data_limit  = 50000\n",
        "\n",
        "xin         = None\n",
        "gradient    = None\n",
        "numerator   = None\n",
        "denominator = None\n",
        "reference   = None\n",
        "\n",
        "print('Data shape: (n_samples, height, width, channels)')\n",
        "print(xin.shape)\n",
        "\n",
        "n_lambda_samples = 100\n",
        "lambda_samples_delta = 0.002\n",
        "lambda_errors = np.zeros((xin.shape[0], n_lambda_samples))\n",
        "global_lambda = np.zeros(xin.shape[0])\n",
        "result = np.zeros((xin.shape[0], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWXb9xKDkYBo"
      },
      "source": [
        "## Vizualizáció\n",
        "\n",
        "Mielőtt nekilátunk a TV regularizáció megvalósításához, vizualizáljuk az adatokat!\n",
        "\n",
        "Feladat:\n",
        "* Jelenítsétek meg a *reference*,  *xin*, *gradient*, *numerator*, *denominator* változók *x*-edik mintáját képként egymás mellett az [add_subplot](https://matplotlib.org/3.5.0/api/figure_api.html?highlight=add_subplot#matplotlib.figure.Figure.add_subplot) segítségével! A kirajzoláshoz használjátok a *'hot'* színtérképet!\n",
        "* Készítsetek interaktív \"nézegetőt\", ahol az *x* értékét egy csúszka segítségével lehet állítani! (Tipp: [Interact](https://ipywidgets.readthedocs.io/en/latest/examples/Using%20Interact.html))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op2N0F_osrWZ"
      },
      "source": [
        "def plot_slice(x):\n",
        "  imNum = 5\n",
        "  fig = plt.figure(figsize=(18, 7), dpi= 80)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "998zHM7VxJWk"
      },
      "source": [
        "# interact(...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z28nPr1zgPKQ"
      },
      "source": [
        "## A TV regularizáció λ paraméterének optimalizálása\n",
        "\n",
        "Az ML-EM iterációs séma a következőképpen néz ki TV regularizáció alkalmazása esetén:\n",
        "\n",
        "$$\n",
        "x_{n+1} = x_{n} * \\frac{numerator}{denominator + \\lambda * gradient}\n",
        "$$\n",
        "\n",
        "A TV regularizáció λ paraméterét úgy kell beállítani, hogy $x_{n+1}$ a lehető legközelebb legyen a referenciához (L2 távolság értelmében).\n",
        "\n",
        "Feladat:\n",
        "* Implementáljátok a *get_lambda_errors* függvényt, amely kiszámolja, hogy a különböző λ értékek mellett $x_{n+1}$-nek mekkora lesz az L2 hibája a referenciától! (Emlékeztető: *n_lambda_samples* adja meg, hogy hány darab mintát szeretnénk venni λ-ból, és *lambda_samples_delta* megadja a minták közötti távolságot. A mintavételt nullától kezdjük.)\n",
        "* Iteráljatok végig minden bemeneti adatmintán (*0 … xin.shape[0]*) és mindegyik mintához számoljátok ki, illetve tároljátok el a *global_lambda* tömbbe a legkisebb L2 hibát eredményező λ értéket!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkJVWWPnqTOt"
      },
      "source": [
        "def get_lambda_errors(xin, denominator, gradient, numerator, reference, sample_idx, n_lambda_samples, lambda_samples_delta):\n",
        "    error = np.zeros(n_lambda_samples)\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    return error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coGDY5nDyF-x"
      },
      "source": [
        "# Remark: tqdm adds a progress bar to track the progress of the for loop\n",
        "for i in tqdm(range(0, xin.shape[0])):\n",
        "  pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXtfeVZVlPCp"
      },
      "source": [
        "## Neurális hálózat felépítése és tanítása\n",
        "\n",
        "Feladat:\n",
        "* Implementáljátok a következő modellt:\n",
        "\n",
        "![tv_nn_architecture.png](http://cg.iit.bme.hu/~drnyu/dlvizinf/tv_nn_architecture.png)\n",
        "\n",
        "Minden konvolúciós és dekonvolúciós réteg\n",
        "* kernelmérete 3,\n",
        "* zero (*same*) paddinget használ,\n",
        "* ReLU aktivációjú,\n",
        "* Batch Normalization réteg követi.\n",
        "\n",
        "A konvolúciós szűrők száma legyen rendre 16, 32, 64, míg a dekonvolúciós rétegeké 64, 32, 16! A konvolúciós rétegek között alkalmazzatok average pooling-ot, míg a dekonvolúciós rétegek között upsampling-ot! (Az utolsó konvolúciós, illetve dekonvolúciós réteg után nem kell méretváltoztatás!) A dekonvolúciós rétegek kimeneteihez konkatenáljátok a megfelelő konvolúciós réteg kimenetét (lásd az ábrán a vízszintes nyilak), és ez a konkatenációs réteg legyen a következő dekonvolúciós réteg bemenete!\n",
        "\n",
        "A három Dense réteg 8-8 neuronból álljon, és ReLU aktivációt használjanak! Őket kövesse egy Flatten réteg, majd pedig az output layer, ami egy 1 neuronból álló Dense réteg sigmoid aktivációval!\n",
        "\n",
        "* Tanítsátok be a hálózatot! (A kód ehhez már készen áll, futtassátok le és értelmezzétek!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM9yzPKOTrKe"
      },
      "source": [
        "def get_model(rows, cols):\n",
        "    inputX = Input(shape=(cols, rows, 1), name='x')\n",
        "    inputG = Input(shape=(cols, rows, 1), name='grad')\n",
        "    inputNum = Input(shape=(cols, rows, 1), name='num')\n",
        "\n",
        "    merge0 = Concatenate(axis=-1, name='concat_1')([inputX, inputG, inputNum])\n",
        "    conv1 = # ...\n",
        "    # ...\n",
        "    output = # ...\n",
        "\n",
        "    model = Model(inputs=[inputX, inputG, inputNum], outputs=[output])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQOFcaOwU65N"
      },
      "source": [
        "def train(model, xin, numerator, gradient, global_lambda, prefix):\n",
        "    #plot_model(model, to_file=prefix + '_model.png')\n",
        "    stop_cb = keras.callbacks.EarlyStopping\\\n",
        "        (monitor='val_loss', min_delta=0.01, patience=10, verbose=1, mode='auto')\n",
        "    save_cb = keras.callbacks.ModelCheckpoint(prefix + '_weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
        "                                              save_weights_only=True, period=10)\n",
        "    history = model.fit(x=[xin[:, :, :, :], gradient[:, :, :, :], numerator[:, :, :, :]],\n",
        "                        y=global_lambda[:],\n",
        "                        epochs=20,\n",
        "                        batch_size=256,\n",
        "                        validation_split=0.2,\n",
        "                        shuffle=True,\n",
        "                        callbacks=[save_cb])\n",
        "\n",
        "    #model.save(prefix + '_tv_model.h5')\n",
        "    #model.save_weights(prefix + '_tv_weights.h5')\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x29DPoRnWGVv"
      },
      "source": [
        "\n",
        "model = get_model(32, 32)\n",
        "training_percent = 0.8\n",
        "\n",
        "training_limit_idx = int(data_limit * training_percent)\n",
        "print(\"Training limit: \" + str(training_limit_idx))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss={'output' : 'mean_squared_logarithmic_error'}, optimizer='adam', metrics=['mse'])\n",
        "#plot_model(model, \"model.svg\")\n",
        "\n",
        "train(model, xin[0:training_limit_idx,], numerator[0:training_limit_idx,], gradient[0:training_limit_idx,], global_lambda[0:training_limit_idx,], \"tv_model\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqJhY1Crl3CA"
      },
      "source": [
        "## Kiértékelés\n",
        "\n",
        "A tanítás után kiértékeljük a modellt a többi adaton. Futtassátok le az alábbi kódblokkokat és vizsgáljátok meg a hálózat teljesítményét! Tudtok úgy javítani a hálózaton, hogy jobb eredményt érjen el?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29ruucr2ZqSI"
      },
      "source": [
        "pred = model.predict(x=[xin[training_limit_idx:, :, :, :], gradient[training_limit_idx:, :, :, :], numerator[training_limit_idx:, :, :, :]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml8m0xG-aJqe"
      },
      "source": [
        "plt.plot(global_lambda[training_limit_idx:])\n",
        "plt.plot(pred)\n",
        "plt.legend(['Optimal', 'Predicted'])\n",
        "plt.xlim(700, 1000)\n",
        "plt.xlabel(\"Test number\")\n",
        "plt.ylabel(\"Lambda\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VynFMuyieUPt"
      },
      "source": [
        "errA = np.array(pred)\n",
        "for i in range(pred.size):\n",
        "    errA[i] = global_lambda[training_limit_idx + i] - pred[i]\n",
        "\n",
        "np.histogram(errA)\n",
        "plt.hist(errA, bins='auto')\n",
        "plt.xlim(-0.2, 0.2)\n",
        "plt.xlabel(\"Deviation\")\n",
        "plt.ylabel(\"Number of tests\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}